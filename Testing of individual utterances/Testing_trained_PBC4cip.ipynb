{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eWhaIZq54Sr"
   },
   "source": [
    "# **Testing Trained PBC4cip**\n",
    "\n",
    "This document will explore the testing of individual utterances to dialogue prompts found in the EmpatheticConversations database using the PBC4cip classification algorithm. In order to test the utterances please see further into the document for the random prompt and input a response as you see feet. Remember to keep the following files in the environment:\n",
    "\n",
    "1.   EmpatheticConversations.xlsx - to obtain the prompts\n",
    "2.   Empathyabase.csv - to ensure the format of the utterance is correct\n",
    "3.   trained_pbc4cip.sav - trained PBC4cip classifier on the Empathyabase.csv database.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kBAgTCnCCl91",
    "outputId": "8693e19e-ed5a-4ebe-df8e-c923fc32140a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: paralleldots in d:\\programs\\py38\\lib\\site-packages (3.2.14)\n",
      "Requirement already satisfied: requests in d:\\programs\\py38\\lib\\site-packages (from paralleldots) (2.25.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in d:\\programs\\py38\\lib\\site-packages (from requests->paralleldots) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\programs\\py38\\lib\\site-packages (from requests->paralleldots) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\programs\\py38\\lib\\site-packages (from requests->paralleldots) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\programs\\py38\\lib\\site-packages (from requests->paralleldots) (2020.12.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (d:\\programs\\py38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\programs\\py38\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install paralleldots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H_JXVsFwDAES",
    "outputId": "019e95e6-1ab6-43b9-ed71-818ce1888eee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PBC4cip in d:\\programs\\py38\\lib\\site-packages (0.0.0.8)\n",
      "Requirement already satisfied: numpy in d:\\programs\\py38\\lib\\site-packages (from PBC4cip) (1.21.0)\n",
      "Requirement already satisfied: pandas in d:\\programs\\py38\\lib\\site-packages (from PBC4cip) (2.0.3)\n",
      "Requirement already satisfied: scikit-learn in d:\\programs\\py38\\lib\\site-packages (from PBC4cip) (0.23.1)\n",
      "Requirement already satisfied: tqdm in d:\\programs\\py38\\lib\\site-packages (from PBC4cip) (4.60.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\programs\\py38\\lib\\site-packages (from pandas->PBC4cip) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\programs\\py38\\lib\\site-packages (from pandas->PBC4cip) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\programs\\py38\\lib\\site-packages (from pandas->PBC4cip) (2023.3)\n",
      "Requirement already satisfied: scipy>=0.19.1 in d:\\programs\\py38\\lib\\site-packages (from scikit-learn->PBC4cip) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\programs\\py38\\lib\\site-packages (from scikit-learn->PBC4cip) (0.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\programs\\py38\\lib\\site-packages (from scikit-learn->PBC4cip) (2.1.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\programs\\py38\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->PBC4cip) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (d:\\programs\\py38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\programs\\py38\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install PBC4cip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "id": "04gIUoXavUpq"
   },
   "outputs": [],
   "source": [
    "#Pandas and numpy imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "\n",
    "#PBC4cip import\n",
    "#from PBC4cip import PBC4cip\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "from PBC4cip import PBC4cip\n",
    "from PBC4cip.core.Evaluation import obtainAUCMulticlass\n",
    "from PBC4cip.core.Helpers import get_col_dist, get_idx_val\n",
    "\n",
    "#Pickle import\n",
    "import pickle\n",
    "\n",
    "#Import paralleldots\n",
    "import paralleldots\n",
    "from paralleldots import taxonomy\n",
    "from paralleldots import set_api_key, get_api_key\n",
    "\n",
    "#Import extras\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJv9cVv1Jfw9",
    "outputId": "319e16c4-8e12-410a-fbca-d51d9f791935"
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('EmpatheticConversations.xlsx')\n",
    "df_prepared = pd.read_csv('Empathyabase.csv')\n",
    "prompt_df = df[df['utterance_idx'] == 1]\n",
    "prompt_df = prompt_df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8klrl8_WQ84_"
   },
   "source": [
    "### Paralleldots licence\n",
    "\n",
    "This license is the one used by the creators of this document, the availability of the API might be inconsistent as a result. If you want to make sure you have access, please sign up through paralleldots and use an available license."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NSBnIgMXHijR",
    "outputId": "fe61e9e1-b6a4-4a35-f20b-3ce8baf710f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key: 9x4Ya0ooRZDwypZZzsIXOaNywIM6szzkk6yGZMX8e2U\n"
     ]
    }
   ],
   "source": [
    "paralleldots.set_api_key('9x4Ya0ooRZDwypZZzsIXOaNywIM6szzkk6yGZMX8e2U')\n",
    "print( \"API Key: %s\" % paralleldots.get_api_key() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0i47PC6jIKm"
   },
   "source": [
    "### Paralleldots\n",
    "\n",
    "Definition of functions that get the paralleldots data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "id": "MewLdhzwjLQF"
   },
   "outputs": [],
   "source": [
    "api_key  = get_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "id": "paLAARUbS_gO"
   },
   "outputs": [],
   "source": [
    "#Sentiment analysis\n",
    "def get_sentiment_pd(prompt_values):\n",
    "    prompt_values['Sentiment'] = str(paralleldots.sentiment(response))\n",
    "    return prompt_values\n",
    "#Emotion analysis\n",
    "def get_emotion_pd(prompt_values, api_key):\n",
    "    while(\"Error\" in str(prompt_values['Emotion'])): \n",
    "        prompt_values['Emotion'] = requests.post( \"https://apis.paralleldots.com/v4/emotion\", data= { \"api_key\": api_key, \"text\": response, \"lang_code\": 'en' } ).text\n",
    "        re_emo = re.sub(r\"\\\"\", \"'\", prompt_values['Emotion'])\n",
    "        prompt_values['Emotion'] = re_emo\n",
    "        if \"error-details\" in str(prompt_values['Emotion']):\n",
    "          print(\"Error contacting paralleldots!!!!\")\n",
    "          print(\"Trying again... \")\n",
    "          prompt_values['Emotion'] = 'Error'\n",
    "        else:\n",
    "          prompt_values['Emotion'] = re_emo\n",
    "    return prompt_values\n",
    "#Taxonomic analysis\n",
    "def get_Taxonomy_pd(prompt_values,api_key):\n",
    "    while('Error' in str(prompt_values['Taxonomy'])):\n",
    "        tax = requests.post( \"https://apis.paralleldots.com/v4/taxonomy\", data= { \"api_key\": api_key, \"text\": response } ).text\n",
    "        re_tax = re.sub(r\"\\\"\", \"'\", tax)\n",
    "        prompt_values['Taxonomy'] = re_tax\n",
    "\n",
    "        if \"error-details\" in str(prompt_values['Taxonomy']):\n",
    "            print(\"Error contacting paralleldots!!!!\")\n",
    "            print(\"Trying again... \")\n",
    "            prompt_values['Taxonomy'] = 'Error'\n",
    "        else:\n",
    "            prompt_values['Taxonomy'] = re_tax\n",
    "    return prompt_values\n",
    "#Intent analysis\n",
    "def get_Intent_pd(prompt_values):\n",
    "    prompt_values['Intent'] = str(paralleldots.intent(str(response)))\n",
    "    return prompt_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMY0j4uStPyG"
   },
   "source": [
    "### Utterance processing\n",
    "\n",
    "In this part, we define the functions for utterance processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EQOQ0sjbtOs3",
    "outputId": "c827d8ed-4119-4772-ee36-cc2e4e639833"
   },
   "outputs": [],
   "source": [
    "#Function definitions\n",
    "def sentiment_separator(s,n):\n",
    "  s2 = s[s.find(\":\")+1+s.find('{'):s.find(\"}\")]\n",
    "  s3 = s2[s2.find('{')+1:]\n",
    "  array = s3.split(\", \")\n",
    "  #print(array)\n",
    "  return float(array[n][array[n].find(':')+1:])\n",
    "\n",
    "intents = ['news','query','spam','marketing','feedback','complaint','suggestion','appreciation']\n",
    "num_to_context = {0: 'afraid', 1: 'angry', 2: 'annoyed',3: 'anticipating',4: 'anxious',5: 'apprehensive',6: 'ashamed',\n",
    "                  7: 'caring',8: 'confident',9: 'content', 10: 'devastated', 11: 'disappointed', 12: 'disgusted',\n",
    "                  13: 'embarrassed', 14: 'excited', 15: 'faithful', 16: 'furious', 17: 'grateful', 18: 'guilty', \n",
    "                  19: 'hopeful', 20: 'impressed', 21: 'jealous', 22: 'joyful', 23: 'lonely', 24: 'nostalgic', \n",
    "                  25: 'prepared', 26: 'proud', 27: 'sad', 28: 'sentimental', 29: 'surprised', 30: 'terrified', \n",
    "                  31: 'trusting'}\n",
    "unique_tax_array = ['IMPACT', 'EDUCATION', 'POLITICS', 'ENTERTAINMENT', 'TASTE',\n",
    "                    'SPORTS', 'HEALTHYLIVING', 'GREEN', 'BUSINESS', 'WORLDPOST',\n",
    "                    'TECH', 'SCIENCE', 'ARTS&CULTURE', 'CRIME', 'TRAVEL', 'RELIGION']\n",
    "def get_intent(s):\n",
    "  s = s[s.find(\"':\")+4:]\n",
    "  arr = s.split(',')\n",
    "  arr\n",
    "  if len(arr) > 5:\n",
    "    s = ''+ arr[4][:arr[4].find('{')]+ arr[4][arr[4].find(\"re':\")+4:]\n",
    "    arr[4] = s\n",
    "    k = arr[5]\n",
    "    k = k[k.find(': {')+3:]\n",
    "    arr[5] = k\n",
    "    t = arr[7]\n",
    "    t = t[:t.find(\"}}\")]\n",
    "    arr[7] = t\n",
    "  else:\n",
    "    arr[4] = arr[4][:arr[4].find(\"}}\")]\n",
    "    arr.append(\"'complaint': 0.0\")\n",
    "    arr.append(\"'suggestion': 0.0\")\n",
    "    arr.append(\"'appreciation': 0.0\")\n",
    "  for i in range(len(arr)):\n",
    "    arr[i] = arr[i].replace(\"'\", \"\")\n",
    "    arr[i] = arr[i].replace(\" \", \"\")\n",
    "    val = arr[i].split(':')\n",
    "    arr[i] = [val[0],float(val[1])]\n",
    "  return arr\n",
    "\n",
    "def obtain_tax_sc(s):\n",
    "#s = df['Taxonomy'][0]\n",
    "  s = s[s.find(\"[\")+1:]\n",
    "  s = s[s.find(\"{\")+1:s.find(\"}]}\")]\n",
    "  s = s.split('},{')\n",
    "  for i in range(len(s)):\n",
    "    arr = s[i].split(',')\n",
    "    new_arr = [arr[1][arr[1].find(\":'\")+2:len(arr[1])-1],float(arr[0][arr[0].find(':')+1:])]\n",
    "    #print(new_arr)\n",
    "    s[i] = new_arr\n",
    "  return s\n",
    "\n",
    "def obtain_tax(s):\n",
    "  s = s[s.find(\"[\")+1:]\n",
    "  s = s.split(',')\n",
    "  #print(s)\n",
    "  for x in s:\n",
    "    if 'tag' not in s:\n",
    "      s.remove(x)\n",
    "  for i in range(len(s)):\n",
    "    s[i] = s[i][s[i].find(':')+2:s[i].find(\"}\")-1]\n",
    "  return s\n",
    "\n",
    "\n",
    "def process_utterance(prompt_values):\n",
    "    #Sentiment separation\n",
    "    prompt_values['Negative_score'] = sentiment_separator(prompt_values['Sentiment'],0)\n",
    "    prompt_values['Neutral_score'] = sentiment_separator(prompt_values['Sentiment'],1)\n",
    "    prompt_values['Positivity_score'] = sentiment_separator(prompt_values['Sentiment'],2)\n",
    "    #Context encoding\n",
    "    context_dict = dict((v, k) for k, v in num_to_context.items())\n",
    "    prompt_values['context_encoded'] = context_dict[prompt_values['context']]\n",
    "    #Emotion separation\n",
    "    emo_str = str(prompt_values['Emotion'])\n",
    "    emo_str = emo_str[emo_str.find(':{')+3:emo_str.find('}}')]\n",
    "    emo_arr = emo_str.split(',')\n",
    "    emo_dic = {}\n",
    "    for x in emo_arr:\n",
    "      val = x.split(\":\")\n",
    "      val[0] = re.sub(r\"\\'\", \"\", val[0])\n",
    "      emo_dic.update({re.match(r'[A-Za-z]*',val[0])[0]:float(val[1])})\n",
    "    for emo in emo_dic:\n",
    "      prompt_values[emo] = emo_dic[emo]\n",
    "    #Intent separation\n",
    "    intent_array = get_intent(prompt_values['Intent'])\n",
    "    for x in intent_array:\n",
    "      prompt_values[str(x[0])] = x[1]\n",
    "    #Taxonomy separation\n",
    "    tax_dict = {}\n",
    "    tax_array = obtain_tax_sc(prompt_values['Taxonomy'].strip())\n",
    "    for tax in tax_array:\n",
    "      tax_dict.update({tax[0]:tax[1]})\n",
    "    tax_dict\n",
    "    for tax in unique_tax_array:\n",
    "      if tax in tax_dict:\n",
    "        prompt_values[tax] = tax_dict[tax]\n",
    "      else:\n",
    "        prompt_values[tax] = float(0)\n",
    "    return prompt_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uWBnhCjnndzF",
    "outputId": "511cbfc2-caaa-400e-f905-60c7010a872b"
   },
   "outputs": [],
   "source": [
    "def pop_features(prompt_values):\n",
    "    #Getting rid of unnecessary features\n",
    "    prompt_values.pop('context')\n",
    "    prompt_values.pop('conv_id')\n",
    "    prompt_values.pop('utterance')\n",
    "    prompt_values.pop('prompt')\n",
    "    prompt_values.pop('Sentiment')\n",
    "    prompt_values.pop('Emotion')\n",
    "    prompt_values.pop('Intent')\n",
    "    prompt_values.pop('speaker_idx')\n",
    "    prompt_values.pop('Taxonomy')\n",
    "    return prompt_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "id": "vTX1o9mdKX35"
   },
   "outputs": [],
   "source": [
    "#Initializing values\n",
    "def initialize_value(prompt_values, utterance,prompt,df):\n",
    "    for c in df.columns:\n",
    "      prompt_values.update({c:prompt[c]})\n",
    "    prompt_values['utterance_idx'] = 2\n",
    "    prompt_values['speaker_idx'] = prompt_values['speaker_idx']+1\n",
    "    prompt_values['utterance'] = utterance\n",
    "    prompt_values['ut_len'] = len(utterance)\n",
    "    prompt_values['Talker'] = 2\n",
    "    prompt_values['Emotion'] = 'Error'\n",
    "    prompt_values['Taxonomy'] = 'Error'\n",
    "    return prompt_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_utterance_full(utt, prompt_values, dataframe, api, promp):\n",
    "    prompt_values = initialize_value(prompt_values, utt, promp, dataframe)\n",
    "    prompt_values = get_sentiment_pd(prompt_values)\n",
    "    prompt_values = get_emotion_pd(prompt_values, api)\n",
    "    prompt_values = get_Taxonomy_pd(prompt_values, api)\n",
    "    prompt_values = get_Intent_pd(prompt_values)\n",
    "    prompt_values = process_utterance(prompt_values)\n",
    "    prompt_values = pop_features(prompt_values)\n",
    "    return prompt_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataframe_format(df_to_copy, utterance):\n",
    "    df_prepared2 = df_to_copy.copy()\n",
    "    df_prepared2.loc[len(df_prepared2)] = utterance\n",
    "    test = pd.DataFrame(df_prepared2, index=[len(df_prepared2)-1])\n",
    "    test['Empathy'] = test['Empathy'].astype('string')\n",
    "    test[\"utterance_idx\"] = test[\"utterance_idx\"].astype('category')\n",
    "    test[\"Talker\"] = test[\"Talker\"].astype('category')\n",
    "    test[\"context_encoded\"] = test[\"context_encoded\"].astype('category')\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_predictions(model_filename,dataframe):\n",
    "    X1_test = dataframe.drop(columns=['Empathy'])\n",
    "    Y1_test = dataframe.drop(columns=X1_test.columns)\n",
    "    #filename = 'trained_pbc4cip.sav'\n",
    "    # load the model from disk\n",
    "    loaded_model = pickle.load(open(model_filename, 'rb'))\n",
    "    y_pred = loaded_model.predict(X1_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your conversation partner says: \n",
      "I love volunteering.\n"
     ]
    }
   ],
   "source": [
    "number_of_prompt = random.randint(0,len(prompt_df))\n",
    "#number_of_prompt = 27\n",
    "prompt = prompt_df.iloc[number_of_prompt]\n",
    "print(\"Your conversation partner says: \")\n",
    "print(prompt['utterance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cknXN6rLQVKU",
    "outputId": "8c597033-3e37-433d-f9f2-d3fb771a4b33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love it very much too! \n"
     ]
    }
   ],
   "source": [
    "response = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'utterance_idx': 2,\n",
       " 'ut_len': 25,\n",
       " 'Empathy': 3,\n",
       " 'Talker': 2,\n",
       " 'Negative_score': 0.01,\n",
       " 'Neutral_score': 0.128,\n",
       " 'Positivity_score': 0.862,\n",
       " 'context_encoded': 7,\n",
       " 'Sad': 0.0526198349,\n",
       " 'Excited': 0.2249661564,\n",
       " 'Angry': 0.0345385505,\n",
       " 'Fear': 0.1638114188,\n",
       " 'Bored': 0.0,\n",
       " 'Happy': 0.5240640393,\n",
       " 'news': 0.001,\n",
       " 'query': 0.032,\n",
       " 'spam': 0.195,\n",
       " 'marketing': 0.013,\n",
       " 'feedback': 0.759,\n",
       " 'complaint': 0.002,\n",
       " 'suggestion': 0.003,\n",
       " 'appreciation': 0.995,\n",
       " 'IMPACT': 0.1361103207,\n",
       " 'EDUCATION': 0.0,\n",
       " 'POLITICS': 0.0,\n",
       " 'ENTERTAINMENT': 0.5995883346,\n",
       " 'TASTE': 0.0,\n",
       " 'SPORTS': 0.0,\n",
       " 'HEALTHYLIVING': 0.0,\n",
       " 'GREEN': 0.0,\n",
       " 'BUSINESS': 0.0,\n",
       " 'WORLDPOST': 0.0,\n",
       " 'TECH': 0.1640076041,\n",
       " 'SCIENCE': 0.0,\n",
       " 'ARTS&CULTURE': 0.0,\n",
       " 'CRIME': 0.0,\n",
       " 'TRAVEL': 0.0,\n",
       " 'RELIGION': 0.0}"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterance_values = {}\n",
    "utterance_values = process_utterance_full(response,utterance_values,df,api_key, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AuIh1CILyWP7"
   },
   "source": [
    "## Classification\n",
    "\n",
    "In this section, we carry out classification using the saved PBC4cip model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "id": "4m1ogWJyvZ-1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier predicts that your response presents an empathy level of: 4 on a scale from 1 to 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "ut_to_df =  to_dataframe_format(df_prepared,utterance_values)\n",
    "#print(ut_to_df)\n",
    "filename = 'trained_pbc4cip.sav'\n",
    "prediction = obtain_predictions(filename,ut_to_df)\n",
    "print(\"The classifier predicts that your response presents an empathy level of: \"+ str(prediction[-1]) +\" on a scale from 1 to 5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples\n",
    "\n",
    "We include some examples of exchange pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your conversation partner says: \n",
      "I love volunteering.\n",
      "You say:\n",
      "I love it very much too!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier predicts that your response presents an empathy level of: 4 on a scale from 1 to 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "prompt = prompt_df.iloc[27]\n",
    "print(\"Your conversation partner says: \")\n",
    "print(prompt['utterance'])\n",
    "response = \"I love it very much too!\"\n",
    "print(\"You say:\")\n",
    "print(response)\n",
    "\n",
    "utterance_values = {}\n",
    "utterance_values = process_utterance_full(response,utterance_values,df,api_key, prompt)\n",
    "ut_to_df =  to_dataframe_format(df_prepared,utterance_values)\n",
    "filename = 'trained_pbc4cip.sav'\n",
    "prediction = obtain_predictions(filename,ut_to_df)\n",
    "\n",
    "print(\"The classifier predicts that your response presents an empathy level of: \"+ str(prediction[-1]) +\" on a scale from 1 to 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your conversation partner says: \n",
      "Last week a friend of mine won $2000 on a scratch off ticket. I buy those things all the time and never win squat.\n",
      "You say:\n",
      "I am so glad you didn't win \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier predicts that your response presents an empathy level of: 1 on a scale from 1 to 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "prompt = prompt_df.iloc[303]\n",
    "print(\"Your conversation partner says: \")\n",
    "print(prompt['utterance'])\n",
    "response = \"I am so glad you didn't win \"\n",
    "print(\"You say:\")\n",
    "print(response)\n",
    "\n",
    "utterance_values = {}\n",
    "utterance_values = process_utterance_full(response,utterance_values,df,api_key, prompt)\n",
    "ut_to_df =  to_dataframe_format(df_prepared,utterance_values)\n",
    "filename = 'trained_pbc4cip.sav'\n",
    "prediction = obtain_predictions(filename,ut_to_df)\n",
    "\n",
    "print(\"The classifier predicts that your response presents an empathy level of: \"+ str(prediction[-1]) +\" on a scale from 1 to 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your conversation partner says: \n",
      "Man.....my cat died:( I feel horrible.\n",
      "You say:\n",
      "Really? I feel fantastic!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier predicts that your response presents an empathy level of: 2 on a scale from 1 to 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "prompt = prompt_df.iloc[71]\n",
    "print(\"Your conversation partner says: \")\n",
    "print(prompt['utterance'])\n",
    "response = \"Really? I feel fantastic!\"\n",
    "print(\"You say:\")\n",
    "print(response)\n",
    "\n",
    "utterance_values = {}\n",
    "utterance_values = process_utterance_full(response,utterance_values,df,api_key, prompt)\n",
    "ut_to_df =  to_dataframe_format(df_prepared,utterance_values)\n",
    "filename = 'trained_pbc4cip.sav'\n",
    "prediction = obtain_predictions(filename,ut_to_df)\n",
    "\n",
    "print(\"The classifier predicts that your response presents an empathy level of: \"+ str(prediction[-1]) +\" on a scale from 1 to 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your conversation partner says: \n",
      "oh boy....I just screwed my whole life up and I want to die\n",
      "You say:\n",
      "I don't really care\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier predicts that your response presents an empathy level of: 1 on a scale from 1 to 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "prompt = prompt_df.iloc[124]\n",
    "print(\"Your conversation partner says: \")\n",
    "print(prompt['utterance'])\n",
    "response = \"I don't really care\"\n",
    "print(\"You say:\")\n",
    "print(response)\n",
    "\n",
    "utterance_values = {}\n",
    "utterance_values = process_utterance_full(response,utterance_values,df,api_key, prompt)\n",
    "ut_to_df =  to_dataframe_format(df_prepared,utterance_values)\n",
    "filename = 'trained_pbc4cip.sav'\n",
    "prediction = obtain_predictions(filename,ut_to_df)\n",
    "\n",
    "print(\"The classifier predicts that your response presents an empathy level of: \"+ str(prediction[-1]) +\" on a scale from 1 to 5\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
