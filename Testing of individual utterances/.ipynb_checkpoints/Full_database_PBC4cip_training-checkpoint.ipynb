{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CqtmuAP-5Hte"
   },
   "source": [
    "# Training of PBC4cip\n",
    "\n",
    "In this document, we train and save a version of PBC4cip using the entire database. The databse presents the following format:\n",
    "\n",
    "*   Empathyabase.csv\n",
    "\n",
    "The result from this code will be a saved version of PBC4cip that can be used in other code, the output will be:\n",
    "\n",
    "1.   A .sav file with the format: trained_pbc4cip.sav\n",
    "\n",
    "\n",
    "### WARNING: The PBC4cip python implementation takes a long time to run. Around an hour per fold. It is much more maneagable to carry out the classification process using this specific classifier in WEKA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k5321bQJiiGy",
    "outputId": "bcc8b05b-a16d-4f75-a60d-75de145b8235"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pbc4cip in d:\\programs\\py38\\lib\\site-packages (0.0.0.8)\n",
      "Requirement already satisfied: numpy in d:\\programs\\py38\\lib\\site-packages (from pbc4cip) (1.21.0)\n",
      "Requirement already satisfied: pandas in d:\\programs\\py38\\lib\\site-packages (from pbc4cip) (2.0.3)\n",
      "Requirement already satisfied: scikit-learn in d:\\programs\\py38\\lib\\site-packages (from pbc4cip) (0.23.1)\n",
      "Requirement already satisfied: tqdm in d:\\programs\\py38\\lib\\site-packages (from pbc4cip) (4.60.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\programs\\py38\\lib\\site-packages (from pandas->pbc4cip) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\programs\\py38\\lib\\site-packages (from pandas->pbc4cip) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\programs\\py38\\lib\\site-packages (from pandas->pbc4cip) (2023.3)\n",
      "Requirement already satisfied: scipy>=0.19.1 in d:\\programs\\py38\\lib\\site-packages (from scikit-learn->pbc4cip) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\programs\\py38\\lib\\site-packages (from scikit-learn->pbc4cip) (0.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\programs\\py38\\lib\\site-packages (from scikit-learn->pbc4cip) (2.1.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\programs\\py38\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->pbc4cip) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (d:\\programs\\py38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\programs\\py38\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install pbc4cip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "deRuJHCogisr"
   },
   "outputs": [],
   "source": [
    "#Importing of libraries necessary for classification and manipulation of database\n",
    "\n",
    "from PBC4cip import PBC4cip\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "from PBC4cip import PBC4cip\n",
    "from PBC4cip.core.Evaluation import obtainAUCMulticlass\n",
    "from PBC4cip.core.Helpers import get_col_dist, get_idx_val\n",
    "\n",
    "\n",
    "#Import pickle to save the model\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z6fzKMzY8av2"
   },
   "source": [
    "## Creation of classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UPRbQW8mh4kE"
   },
   "outputs": [],
   "source": [
    "#Creation of classifier\n",
    "pbc = PBC4cip(tree_count = 100) # 100 tree cound og\n",
    "\n",
    "\n",
    "#Generation of classification array\n",
    "classifiers = [pbc]\n",
    "class_names = ['PBC4CIP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vd4UtILm8hxp"
   },
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v-QQ5W_WizlL",
    "outputId": "e5566941-97ba-4cf0-977e-1ba0c08f025b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    }
   ],
   "source": [
    "#Values for each classifier are stored in the array\n",
    "acc_list = []\n",
    "recall_list = []\n",
    "precision_list = []\n",
    "auc_list = []\n",
    "confusion_list = []\n",
    "\n",
    "#Scoring function for PBC4CIP\n",
    "def score(predicted, y):\n",
    "        y_class_dist = get_col_dist(y[f'{y.columns[0]}'])\n",
    "        real = list(map(lambda instance: get_idx_val(y_class_dist, instance), y[f'{y.columns[0]}']))\n",
    "        numClasses = len(y_class_dist)\n",
    "        confusion = [[0]* numClasses for i in range(numClasses)]\n",
    "        classified_as = 0\n",
    "        error_count = 0\n",
    "\n",
    "        for i in range(len(real)):\n",
    "            if real[i] != predicted[i]:\n",
    "                error_count = error_count + 1\n",
    "            confusion[real[i]][predicted[i]] = confusion[real[i]][predicted[i]] + 1\n",
    "\n",
    "        acc = 100.0 * (len(real) - error_count) / len(real)\n",
    "        auc = obtainAUCMulticlass(confusion, numClasses)\n",
    "\n",
    "        return confusion, acc, auc\n",
    "\n",
    "\n",
    "for cls in classifiers:\n",
    "\n",
    "  #Training the classifier\n",
    "\n",
    "  data_tra = pd.read_csv('Empathyabase.csv')\n",
    "\n",
    "  #Preparation\n",
    "  # We ensure that the variables are taken as categories and not integers or floats\n",
    "\n",
    "  data_tra['Empathy'] = data_tra['Empathy'].astype('string')\n",
    "  data_tra[\"utterance_idx\"] = data_tra[\"utterance_idx\"].astype('category')\n",
    "  data_tra[\"Talker\"] = data_tra[\"Talker\"].astype('category')\n",
    "  data_tra[\"context_encoded\"] = data_tra[\"context_encoded\"].astype('category')\n",
    "\n",
    "  #Separate target values for training\n",
    "\n",
    "  X1_train = data_tra.drop(columns=['Empathy'])\n",
    "  Y1_train = data_tra.drop(columns=X1_train.columns)\n",
    "  #PBC4CIP\n",
    "  patterns = cls.fit(X1_train, Y1_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YF1Z7ZDq-PgT"
   },
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "5Sjp9H1Q-Ng_"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'trained_pbc4cip.sav'\n",
    "pickle.dump(pbc, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
