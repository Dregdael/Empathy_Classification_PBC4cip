{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eWhaIZq54Sr"
   },
   "source": [
    "# **Testing Trained PBC4cip**\n",
    "\n",
    "This document will explore the testing of individual utterances to dialogue prompts found in the EmpatheticConversations database using the PBC4cip classification algorithm. In order to test the utterances please see further into the document for the random prompt and input a response as you see feet. Remember to keep the following files in the environment:\n",
    "\n",
    "1.   EmpatheticConversations.xlsx - to obtain the prompts\n",
    "2.   Empathyabase.csv - to ensure the format of the utterance is correct\n",
    "3.   trained_pbc4cip.sav - trained PBC4cip classifier on the Empathyabase.csv database.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kBAgTCnCCl91",
    "outputId": "8693e19e-ed5a-4ebe-df8e-c923fc32140a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: paralleldots in d:\\programs\\py38\\lib\\site-packages (3.2.14)\n",
      "Requirement already satisfied: requests in d:\\programs\\py38\\lib\\site-packages (from paralleldots) (2.25.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in d:\\programs\\py38\\lib\\site-packages (from requests->paralleldots) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\programs\\py38\\lib\\site-packages (from requests->paralleldots) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\programs\\py38\\lib\\site-packages (from requests->paralleldots) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\programs\\py38\\lib\\site-packages (from requests->paralleldots) (2020.12.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (d:\\programs\\py38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\programs\\py38\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install paralleldots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H_JXVsFwDAES",
    "outputId": "019e95e6-1ab6-43b9-ed71-818ce1888eee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PBC4cip in d:\\programs\\py38\\lib\\site-packages (0.0.0.8)\n",
      "Requirement already satisfied: numpy in d:\\programs\\py38\\lib\\site-packages (from PBC4cip) (1.21.0)\n",
      "Requirement already satisfied: pandas in d:\\programs\\py38\\lib\\site-packages (from PBC4cip) (2.0.3)\n",
      "Requirement already satisfied: scikit-learn in d:\\programs\\py38\\lib\\site-packages (from PBC4cip) (0.23.1)\n",
      "Requirement already satisfied: tqdm in d:\\programs\\py38\\lib\\site-packages (from PBC4cip) (4.60.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\programs\\py38\\lib\\site-packages (from pandas->PBC4cip) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\programs\\py38\\lib\\site-packages (from pandas->PBC4cip) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\programs\\py38\\lib\\site-packages (from pandas->PBC4cip) (2023.3)\n",
      "Requirement already satisfied: scipy>=0.19.1 in d:\\programs\\py38\\lib\\site-packages (from scikit-learn->PBC4cip) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\programs\\py38\\lib\\site-packages (from scikit-learn->PBC4cip) (0.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\programs\\py38\\lib\\site-packages (from scikit-learn->PBC4cip) (2.1.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\programs\\py38\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->PBC4cip) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (d:\\programs\\py38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\programs\\py38\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install PBC4cip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "04gIUoXavUpq"
   },
   "outputs": [],
   "source": [
    "#Pandas and numpy imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "\n",
    "#PBC4cip import\n",
    "#from PBC4cip import PBC4cip\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "from PBC4cip import PBC4cip\n",
    "from PBC4cip.core.Evaluation import obtainAUCMulticlass\n",
    "from PBC4cip.core.Helpers import get_col_dist, get_idx_val\n",
    "\n",
    "#Pickle import\n",
    "import pickle\n",
    "\n",
    "#Import paralleldots\n",
    "import paralleldots\n",
    "from paralleldots import taxonomy\n",
    "from paralleldots import set_api_key, get_api_key\n",
    "\n",
    "#Import extras\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJv9cVv1Jfw9",
    "outputId": "319e16c4-8e12-410a-fbca-d51d9f791935"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('EmpatheticConversations.xlsx')\n",
    "df_prepared = pd.read_csv('Empathyabase.csv')\n",
    "prompt_df = df[df['utterance_idx'] == 1]\n",
    "prompt_df = prompt_df.reset_index()\n",
    "len(prompt_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8klrl8_WQ84_"
   },
   "source": [
    "## Set up paralleldots licence\n",
    "\n",
    "This license is the one used by the creators of this document, the availability of the API might be inconsistent as a result. If you want to make sure you have access, please sign up through paralleldots and use an available license."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NSBnIgMXHijR",
    "outputId": "fe61e9e1-b6a4-4a35-f20b-3ce8baf710f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key: 9x4Ya0ooRZDwypZZzsIXOaNywIM6szzkk6yGZMX8e2U\n"
     ]
    }
   ],
   "source": [
    "paralleldots.set_api_key('9x4Ya0ooRZDwypZZzsIXOaNywIM6szzkk6yGZMX8e2U')\n",
    "print( \"API Key: %s\" % paralleldots.get_api_key() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2atlQxK5lllz"
   },
   "source": [
    "#**INTERACTION SECTION**\n",
    "\n",
    "Please read the prompt given to you and give an appropriate input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vtyJb0SIv7mE",
    "outputId": "4160cc29-c4b3-4841-c62a-cff18bcd5190"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your conversation partner says: \n",
      "I was recently on a mule ride in the Grand Canyon of Arizona! I really had to put a lot of faith in the mule though, because there were a bunch of sheer drops on the trail!\n"
     ]
    }
   ],
   "source": [
    "number_of_prompt = random.randint(0,len(prompt_df))\n",
    "prompt = prompt_df.iloc[number_of_prompt]\n",
    "print(\"Your conversation partner says: \")\n",
    "print(prompt['utterance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cknXN6rLQVKU",
    "outputId": "8c597033-3e37-433d-f9f2-d3fb771a4b33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mules are very trustworthy animals, I really love them\n"
     ]
    }
   ],
   "source": [
    "response = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o5yDYPL0OI5Z",
    "outputId": "370f7bbe-01c1-4263-8cb4-f3dae086eb5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You say: \n",
      "Mules are very trustworthy animals, I really love them\n"
     ]
    }
   ],
   "source": [
    "print(\"You say: \")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "vTX1o9mdKX35"
   },
   "outputs": [],
   "source": [
    "#Initializing values\n",
    "df.columns\n",
    "prompt_values = {}\n",
    "\n",
    "for c in df.columns:\n",
    "  prompt_values.update({c:prompt[c]})\n",
    "\n",
    "prompt_values['utterance_idx'] = 2\n",
    "prompt_values['speaker_idx'] = prompt_values['speaker_idx']+1\n",
    "prompt_values['utterance'] = response\n",
    "prompt_values['ut_len'] = len(response)\n",
    "prompt_values['Talker'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0i47PC6jIKm"
   },
   "source": [
    "# **Paralleldots**\n",
    "\n",
    "This part of the document gets the data from paralleldots.\n",
    "\n",
    "\n",
    "# WARNING: ERRORS MIGHT APPEAR DURING FETCHING OF DATA, CHECK OUTPUT.\n",
    "\n",
    "## YOU MIGHT NEED TO RUN THESE STEPS UNTIL NO ERRORS ARE STATED TO HAVE BEEN FOUND WHILE CONTACTING PARALLELDOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "MewLdhzwjLQF"
   },
   "outputs": [],
   "source": [
    "api_key  = get_api_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zupPE421LWi3"
   },
   "source": [
    "### **Sentiment analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "paLAARUbS_gO"
   },
   "outputs": [],
   "source": [
    "prompt_values['Sentiment'] = str(paralleldots.sentiment(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lY2hyGuSU2Yo"
   },
   "source": [
    "### **Emotion analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "wtQKCRQzU9WL"
   },
   "outputs": [],
   "source": [
    "#prompt_values['Emotion'] = paralleldots.emotion(response,'en')\n",
    "prompt_values['Emotion'] = requests.post( \"https://apis.paralleldots.com/v4/emotion\", data= { \"api_key\": api_key, \"text\": response, \"lang_code\": 'en' } ).text\n",
    "re_emo = re.sub(r\"\\\"\", \"'\", prompt_values['Emotion'])\n",
    "prompt_values['Emotion'] = re_emo\n",
    "\n",
    "if \"error-details\" in str(prompt_values['Emotion']):\n",
    "  print(\"Error contacting paralleldots!!!!\")\n",
    "  print(\"Setting up dummy values for emotion... \")\n",
    "  prompt_values['Emotion'] = \"{'emotion':{'Happy': 0.000000, 'Fear': 0.000000, 'Sad': 0.000000, 'Bored': 0.000000, 'Angry': 0.000000, 'Excited': 0.000000}}\"\n",
    "  print(\"DO NOT TRUST CLASSIFICATION RESULT\")\n",
    "  print(\"RECOMMENDATION: RESTART CODE BLOCK\")\n",
    "  print()\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PiBWlav8p5fj"
   },
   "source": [
    "### **Taxonomic analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "K8TReEqXYoqJ"
   },
   "outputs": [],
   "source": [
    "#prompt_values['Taxonomy'] = paralleldots.taxonomy(response)\n",
    "\n",
    "tax = requests.post( \"https://apis.paralleldots.com/v4/taxonomy\", data= { \"api_key\": api_key, \"text\": response } ).text\n",
    "re_tax = re.sub(r\"\\\"\", \"'\", tax)\n",
    "prompt_values['Taxonomy'] = re_tax\n",
    "\n",
    "if \"error-details\" in str(prompt_values['Taxonomy']):\n",
    "  print(\"Error contacting paralleldots!!!!\")\n",
    "  print(\"Setting up dummy values for Taxonomy... \")\n",
    "  prompt_values['Taxonomy'] = \"{'taxonomy':[{'confidence_score': 0.00000, 'tag': 'IMPACT'}, {'confidence_score': 0.00000, 'tag': 'EDUCATION'}, {'confidence_score': 0.00000, 'tag': 'POLITICS'}]}\"\n",
    "  print(\"DO NOT TRUST CLASSIFICATION RESULT\")\n",
    "  print(\"RECOMMENDATION: RESTART CODE BLOCK\")\n",
    "  print()\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-irQvVrfp9Fv"
   },
   "source": [
    "### **Intent analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "smXjZRI4Z4eE"
   },
   "outputs": [],
   "source": [
    "prompt_values['Intent'] = str(paralleldots.intent(str(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMY0j4uStPyG"
   },
   "source": [
    "# Utterance processing\n",
    "\n",
    "In this section, we process the utterance so that it can be fed to the classifier. In general, it is just the separation of the paralleldots data and setting up the EC features so that it is compatible with the database format used to train the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EQOQ0sjbtOs3",
    "outputId": "c827d8ed-4119-4772-ee36-cc2e4e639833"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv_id': 'hit:4980_conv:9960',\n",
       " 'utterance_idx': 2,\n",
       " 'context': 'trusting',\n",
       " 'prompt': 'I was recently on a mule ride in the Grand Canyon of Arizona!  I really had to put a lot of faith in the mule though_comma_ because there were a bunch of sheer drops on the trail!',\n",
       " 'speaker_idx': 278,\n",
       " 'utterance': 'Mules are very trustworthy animals, I really love them',\n",
       " 'ut_len': 54,\n",
       " 'Empathy': 4,\n",
       " 'Talker': 2,\n",
       " 'Sentiment': \"{'sentiment': {'negative': 0.114, 'neutral': 0.293, 'positive': 0.593}}\",\n",
       " 'Emotion': \"{'emotion':{'Happy':0.391347547,'Fear':0.1449694537,'Angry':0.040888843,'Bored':0.0,'Excited':0.1329019168,'Sad':0.2898922395}}\",\n",
       " 'Taxonomy': \"{'taxonomy':[{'confidence_score':0.8478633165,'tag':'ENTERTAINMENT'},{'confidence_score':0.0963525102,'tag':'TASTE'},{'confidence_score':0.0159519427,'tag':'POLITICS'}]}\",\n",
       " 'Intent': \"{'intent': {'news': 0.016, 'query': 0.031, 'spam': 0.417, 'marketing': 0.007, 'feedback': {'score': 0.53, 'tag': {'complaint': 0.017, 'suggestion': 0.012, 'appreciation': 0.971}}}}\",\n",
       " 'Negative_score': 0.114,\n",
       " 'Neutral_score': 0.293,\n",
       " 'Positivity_score': 0.593,\n",
       " 'context_encoded': 31,\n",
       " 'Happy': 0.391347547,\n",
       " 'Fear': 0.1449694537,\n",
       " 'Angry': 0.040888843,\n",
       " 'Bored': 0.0,\n",
       " 'Excited': 0.1329019168,\n",
       " 'Sad': 0.2898922395,\n",
       " 'news': 0.016,\n",
       " 'query': 0.031,\n",
       " 'spam': 0.417,\n",
       " 'marketing': 0.007,\n",
       " 'feedback': 0.53,\n",
       " 'complaint': 0.017,\n",
       " 'suggestion': 0.012,\n",
       " 'appreciation': 0.971,\n",
       " 'IMPACT': 0.0,\n",
       " 'EDUCATION': 0.0,\n",
       " 'POLITICS': 0.0159519427,\n",
       " 'ENTERTAINMENT': 0.8478633165,\n",
       " 'TASTE': 0.0963525102,\n",
       " 'SPORTS': 0.0,\n",
       " 'HEALTHYLIVING': 0.0,\n",
       " 'GREEN': 0.0,\n",
       " 'BUSINESS': 0.0,\n",
       " 'WORLDPOST': 0.0,\n",
       " 'TECH': 0.0,\n",
       " 'SCIENCE': 0.0,\n",
       " 'ARTS&CULTURE': 0.0,\n",
       " 'CRIME': 0.0,\n",
       " 'TRAVEL': 0.0,\n",
       " 'RELIGION': 0.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sentiment separation\n",
    "\n",
    "def sentiment_separator(s,n):\n",
    "  s2 = s[s.find(\":\")+1+s.find('{'):s.find(\"}\")]\n",
    "  s3 = s2[s2.find('{')+1:]\n",
    "  array = s3.split(\", \")\n",
    "  #print(array)\n",
    "  return float(array[n][array[n].find(':')+1:])\n",
    "\n",
    "prompt_values['Negative_score'] = sentiment_separator(prompt_values['Sentiment'],0)\n",
    "prompt_values['Neutral_score'] = sentiment_separator(prompt_values['Sentiment'],1)\n",
    "prompt_values['Positivity_score'] = sentiment_separator(prompt_values['Sentiment'],2)\n",
    "\n",
    "#Context encoding\n",
    "\n",
    "num_to_context = {0: 'afraid',\n",
    " 1: 'angry',\n",
    " 2: 'annoyed',\n",
    " 3: 'anticipating',\n",
    " 4: 'anxious',\n",
    " 5: 'apprehensive',\n",
    " 6: 'ashamed',\n",
    " 7: 'caring',\n",
    " 8: 'confident',\n",
    " 9: 'content',\n",
    " 10: 'devastated',\n",
    " 11: 'disappointed',\n",
    " 12: 'disgusted',\n",
    " 13: 'embarrassed',\n",
    " 14: 'excited',\n",
    " 15: 'faithful',\n",
    " 16: 'furious',\n",
    " 17: 'grateful',\n",
    " 18: 'guilty',\n",
    " 19: 'hopeful',\n",
    " 20: 'impressed',\n",
    " 21: 'jealous',\n",
    " 22: 'joyful',\n",
    " 23: 'lonely',\n",
    " 24: 'nostalgic',\n",
    " 25: 'prepared',\n",
    " 26: 'proud',\n",
    " 27: 'sad',\n",
    " 28: 'sentimental',\n",
    " 29: 'surprised',\n",
    " 30: 'terrified',\n",
    " 31: 'trusting'}\n",
    "\n",
    "context_dict = dict((v, k) for k, v in num_to_context.items())\n",
    "\n",
    "prompt_values['context_encoded'] = context_dict[prompt_values['context']]\n",
    "\n",
    "#Emotion separation\n",
    "\n",
    "emo_str = str(prompt_values['Emotion'])\n",
    "emo_str = emo_str[emo_str.find(':{')+3:emo_str.find('}}')]\n",
    "emo_arr = emo_str.split(',')\n",
    "emo_dic = {}\n",
    "for x in emo_arr:\n",
    "  val = x.split(\":\")\n",
    "  val[0] = re.sub(r\"\\'\", \"\", val[0])\n",
    "  emo_dic.update({re.match(r'[A-Za-z]*',val[0])[0]:float(val[1])})\n",
    "\n",
    "for emo in emo_dic:\n",
    "  prompt_values[emo] = emo_dic[emo]\n",
    "\n",
    "#Intent separation\n",
    "\n",
    "intents = ['news','query','spam','marketing','feedback','complaint','suggestion','appreciation']\n",
    "\n",
    "def get_intent(s):\n",
    "  s = s[s.find(\"':\")+4:]\n",
    "  arr = s.split(',')\n",
    "  arr\n",
    "  if len(arr) > 5:\n",
    "    s = ''+ arr[4][:arr[4].find('{')]+ arr[4][arr[4].find(\"re':\")+4:]\n",
    "    arr[4] = s\n",
    "    k = arr[5]\n",
    "    k = k[k.find(': {')+3:]\n",
    "    arr[5] = k\n",
    "    t = arr[7]\n",
    "    t = t[:t.find(\"}}\")]\n",
    "    arr[7] = t\n",
    "  else:\n",
    "    arr[4] = arr[4][:arr[4].find(\"}}\")]\n",
    "    arr.append(\"'complaint': 0.0\")\n",
    "    arr.append(\"'suggestion': 0.0\")\n",
    "    arr.append(\"'appreciation': 0.0\")\n",
    "  for i in range(len(arr)):\n",
    "    arr[i] = arr[i].replace(\"'\", \"\")\n",
    "    arr[i] = arr[i].replace(\" \", \"\")\n",
    "    val = arr[i].split(':')\n",
    "    arr[i] = [val[0],float(val[1])]\n",
    "  return arr\n",
    "\n",
    "intent_array = get_intent(prompt_values['Intent'])\n",
    "for x in intent_array:\n",
    "  prompt_values[str(x[0])] = x[1]\n",
    "\n",
    "#Taxonomy separation\n",
    "\n",
    "unique_tax_array = ['IMPACT', 'EDUCATION', 'POLITICS', 'ENTERTAINMENT', 'TASTE', 'SPORTS', 'HEALTHYLIVING', 'GREEN', 'BUSINESS', 'WORLDPOST', 'TECH', 'SCIENCE', 'ARTS&CULTURE', 'CRIME', 'TRAVEL', 'RELIGION']\n",
    "\n",
    "def obtain_tax(s):\n",
    "  s = s[s.find(\"[\")+1:]\n",
    "  s = s.split(',')\n",
    "  #print(s)\n",
    "  for x in s:\n",
    "    if 'tag' not in s:\n",
    "      s.remove(x)\n",
    "  for i in range(len(s)):\n",
    "    s[i] = s[i][s[i].find(':')+2:s[i].find(\"}\")-1]\n",
    "  return s\n",
    "\n",
    "tax_dict = {}\n",
    "\n",
    "def obtain_tax_sc(s):\n",
    "#s = df['Taxonomy'][0]\n",
    "  s = s[s.find(\"[\")+1:]\n",
    "  s = s[s.find(\"{\")+1:s.find(\"}]}\")]\n",
    "  s = s.split('},{')\n",
    "  for i in range(len(s)):\n",
    "    arr = s[i].split(',')\n",
    "    new_arr = [arr[1][arr[1].find(\":'\")+2:len(arr[1])-1],float(arr[0][arr[0].find(':')+1:])]\n",
    "    #print(new_arr)\n",
    "    s[i] = new_arr\n",
    "  return s\n",
    "\n",
    "tax_array = obtain_tax_sc(prompt_values['Taxonomy'].strip())\n",
    "\n",
    "for tax in tax_array:\n",
    "  tax_dict.update({tax[0]:tax[1]})\n",
    "\n",
    "tax_dict\n",
    "\n",
    "for tax in unique_tax_array:\n",
    "  if tax in tax_dict:\n",
    "    prompt_values[tax] = tax_dict[tax]\n",
    "  else:\n",
    "    prompt_values[tax] = float(0)\n",
    "\n",
    "prompt_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uWBnhCjnndzF",
    "outputId": "511cbfc2-caaa-400e-f905-60c7010a872b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'utterance_idx': 2,\n",
       " 'ut_len': 54,\n",
       " 'Empathy': 4,\n",
       " 'Talker': 2,\n",
       " 'Negative_score': 0.114,\n",
       " 'Neutral_score': 0.293,\n",
       " 'Positivity_score': 0.593,\n",
       " 'context_encoded': 31,\n",
       " 'Happy': 0.391347547,\n",
       " 'Fear': 0.1449694537,\n",
       " 'Angry': 0.040888843,\n",
       " 'Bored': 0.0,\n",
       " 'Excited': 0.1329019168,\n",
       " 'Sad': 0.2898922395,\n",
       " 'news': 0.016,\n",
       " 'query': 0.031,\n",
       " 'spam': 0.417,\n",
       " 'marketing': 0.007,\n",
       " 'feedback': 0.53,\n",
       " 'complaint': 0.017,\n",
       " 'suggestion': 0.012,\n",
       " 'appreciation': 0.971,\n",
       " 'IMPACT': 0.0,\n",
       " 'EDUCATION': 0.0,\n",
       " 'POLITICS': 0.0159519427,\n",
       " 'ENTERTAINMENT': 0.8478633165,\n",
       " 'TASTE': 0.0963525102,\n",
       " 'SPORTS': 0.0,\n",
       " 'HEALTHYLIVING': 0.0,\n",
       " 'GREEN': 0.0,\n",
       " 'BUSINESS': 0.0,\n",
       " 'WORLDPOST': 0.0,\n",
       " 'TECH': 0.0,\n",
       " 'SCIENCE': 0.0,\n",
       " 'ARTS&CULTURE': 0.0,\n",
       " 'CRIME': 0.0,\n",
       " 'TRAVEL': 0.0,\n",
       " 'RELIGION': 0.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Getting rid of unnecessary features\n",
    "prompt_values.pop('context')\n",
    "prompt_values.pop('conv_id')\n",
    "prompt_values.pop('utterance')\n",
    "prompt_values.pop('prompt')\n",
    "prompt_values.pop('Sentiment')\n",
    "prompt_values.pop('Emotion')\n",
    "prompt_values.pop('Intent')\n",
    "prompt_values.pop('speaker_idx')\n",
    "prompt_values.pop('Taxonomy')\n",
    "\n",
    "prompt_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQNIgi_gmlQE"
   },
   "source": [
    "## We carry out the preparation of the database with our new row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "4m1ogWJyvZ-1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n",
      "113\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance_idx</th>\n",
       "      <th>ut_len</th>\n",
       "      <th>Empathy</th>\n",
       "      <th>Talker</th>\n",
       "      <th>Negative_score</th>\n",
       "      <th>Neutral_score</th>\n",
       "      <th>Positivity_score</th>\n",
       "      <th>Happy</th>\n",
       "      <th>Fear</th>\n",
       "      <th>Sad</th>\n",
       "      <th>...</th>\n",
       "      <th>GREEN</th>\n",
       "      <th>BUSINESS</th>\n",
       "      <th>WORLDPOST</th>\n",
       "      <th>TECH</th>\n",
       "      <th>SCIENCE</th>\n",
       "      <th>ARTS&amp;CULTURE</th>\n",
       "      <th>CRIME</th>\n",
       "      <th>TRAVEL</th>\n",
       "      <th>RELIGION</th>\n",
       "      <th>context_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.391348</td>\n",
       "      <td>0.144969</td>\n",
       "      <td>0.289892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    utterance_idx  ut_len Empathy Talker  Negative_score  Neutral_score  \\\n",
       "112             2      54       4      2           0.114          0.293   \n",
       "\n",
       "     Positivity_score     Happy      Fear       Sad  ...  GREEN  BUSINESS  \\\n",
       "112             0.593  0.391348  0.144969  0.289892  ...    0.0       0.0   \n",
       "\n",
       "     WORLDPOST  TECH  SCIENCE  ARTS&CULTURE  CRIME  TRAVEL  RELIGION  \\\n",
       "112        0.0   0.0      0.0           0.0    0.0     0.0       0.0   \n",
       "\n",
       "     context_encoded  \n",
       "112               31  \n",
       "\n",
       "[1 rows x 38 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_prepared2 = read_csv('Empathyabase-1tst.csv')\n",
    "df_prepared2 = df_prepared.copy()\n",
    "\n",
    "df_prepared2.loc[len(df_prepared2)] = prompt_values\n",
    "\n",
    "test = pd.DataFrame(df_prepared2, index=[len(df_prepared2)-1])\n",
    "test['Empathy'] = test['Empathy'].astype('string')\n",
    "test[\"utterance_idx\"] = test[\"utterance_idx\"].astype('category')\n",
    "test[\"Talker\"] = test[\"Talker\"].astype('category')\n",
    "test[\"context_encoded\"] = test[\"context_encoded\"].astype('category')\n",
    "df_prepared2\n",
    "print(len(df_prepared))\n",
    "print(len(df_prepared2))\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AuIh1CILyWP7"
   },
   "source": [
    "# CLASSIFICATION\n",
    "\n",
    "In this section, we carry out classification using the saved PBC4cip model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OL0C57bkKJ00",
    "outputId": "57208bcf-4c48-41dc-c01a-4aa731055297"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    }
   ],
   "source": [
    "\n",
    "X1_test = test.drop(columns=['Empathy'])\n",
    "Y1_test = test.drop(columns=X1_test.columns)\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'trained_pbc4cip.sav'\n",
    "\n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "y_pred = loaded_model.predict(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3-T1vHkNygoh",
    "outputId": "c2f36d80-a827-4c83-e7dc-8295eb5c4c69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier predicts that your response presents an empathy level of: 4 on a scale from 1 to 5\n"
     ]
    }
   ],
   "source": [
    "print(\"The classifier predicts that your response presents an empathy level of: \"+ str(y_pred[-1]) +\" on a scale from 1 to 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
